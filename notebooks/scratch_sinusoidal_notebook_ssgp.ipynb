{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import online_gp\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(N=50, shift=0):\n",
    "    x = torch.randn(N,1) + shift\n",
    "    y = (torch.sin(3. * x) + 0.1 * torch.randn_like(x)).view(-1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(mll, model, optimizer, x, y, num_steps=1000):\n",
    "    for i in range(num_steps):\n",
    "        loss = -mll(model(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if i % (num_steps // 10 if num_steps > 10 else 1) == 0:\n",
    "            print(\"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_basic_plot(model, x, y, old_x=None, old_y=None, bounds=(-6., 6.)):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_x = torch.linspace(*bounds).view(-1,1)\n",
    "        pred_dist = vargp_model(test_x)\n",
    "        pred_induc = vargp_model(vargp_model.variational_strategy.inducing_points.data.view(-1,1))\n",
    "        \n",
    "    plt.plot(test_x, pred_dist.mean, label = \"Predictive Mean\")\n",
    "    plt.fill_between(test_x.view(-1), *[x.detach() for x in pred_dist.confidence_region()], alpha = 0.3)\n",
    "    \n",
    "    plt.scatter(x, y, color = \"black\", label = \"Current Data\")\n",
    "    plt.scatter(vargp_model.variational_strategy.inducing_points.data, pred_induc.mean.detach(), \n",
    "            color = \"red\", marker=\"x\", label = \"Inducing Points\")\n",
    "    if old_x is not None:\n",
    "        plt.scatter(old_x, old_y, color = \"grey\", alpha = 0.5, label = \"Old Data\")\n",
    "        \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "vargp_model = online_gp.models.VariationalGPModel(torch.randn(25, 1), streaming=False, likelihood = likelihood)\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood=likelihood, model=vargp_model, num_data=x.shape[-2], beta = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(list(vargp_model.parameters()) + list(likelihood.parameters()), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model(mll, vargp_model, optimizer, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_basic_plot(vargp_model, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x, new_y = get_data(N = 5, shift = 6)\n",
    "\n",
    "induc_to_keep = torch.randperm(25)[:22]\n",
    "new_x_to_keep = torch.randperm(new_x.shape[0])[:3]\n",
    "new_inducing = torch.cat((\n",
    "    new_x[new_x_to_keep], \n",
    "    vargp_model.variational_strategy.inducing_points[induc_to_keep]\n",
    "),dim=0).detach()\n",
    "\n",
    "vargp_model.update_variational_parameters(new_x, new_y, new_inducing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vargp_model.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vargp_model.zero_grad()\n",
    "vargp_model.train()\n",
    "\n",
    "mll = gpytorch.mlls.VariationalELBO(\n",
    "    likelihood=likelihood, \n",
    "    model=vargp_model, \n",
    "    num_data=new_x.shape[-2], \n",
    "    beta = 1.0,\n",
    "    combine_terms=True\n",
    ")\n",
    "optimizer = torch.optim.Adam(list(vargp_model.parameters()) + list(likelihood.parameters()), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model(mll, vargp_model, optimizer, new_x, new_y, num_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_basic_plot(vargp_model, new_x, new_y, old_x=x, old_y=y, bounds=(-3., 12.))\n",
    "plt.ylim((-3., 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(new_inducing, new_inducing - vargp_model.variational_strategy.inducing_points.detach())\n",
    "plt.xlabel(\"Initial Inducing Points\")\n",
    "plt.ylabel(\"Initial Inducing Points - Current Inducing Points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda52eab690427c4f7ea56588deee120c46"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
